# -*- coding: utf-8 -*-
"""01 Student Score Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iE9410Pj7w33R3kPiPeN3-PfVGLbF44n

# Student Exam Score Prediction using Machine Learning

## Introduction

This project explores the factors that influence student academic performance and aims to predict exam scores using machine learning techniques. The dataset, Student Performance Factors (Kaggle), contains information such as study hours, attendance, parental involvement, access to resources, motivation, and more.

Through data preprocessing, exploratory data analysis (EDA), and regression modeling, we build and evaluate a predictive model. The main objective is to identify key features that affect student outcomes and assess how well linear regression can estimate exam performance.

Additionally, we experiment with polynomial regression and feature selection (dropping/keeping certain attributes) to compare performance, ensuring the model is both accurate and interpretable.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

"""# Data Cleaning & Preprocessing

## Data loading and analyzing
"""

dff = pd.read_csv("/content/drive/MyDrive/01 Machine Learning/Internship/ELEVVO/task /StudentPerformanceFactors.csv")
df= dff.copy()
df.head()

df.info()

df.describe()

"""## Missing values filled (mean for numeric, mode for categorical).

"""

df.isnull().sum()

df.shape

# df['Teacher_Quality','Parental_Education_Level','Distance_from_Home']
for col in df:
  # print(df.isnull().sum())
  if df[col].dtype=="object":
    df[col] = df[col].fillna(df[col].mode()[0])
  else:
    df[col] = df[col].fillna(df[col].mean())

df.isnull().sum()

df.info()

# df['Score '].hist()
# plt.scatter(df['StudyHours'], df['Score'])
# sns.boxplot(x='Preparation', y='Score', data=df)
# sns.heatmap(df.corr(), annot=True, cmap="coolwarm")

"""## Converted categorical features using Label Encoding (binary) and One-Hot Encoding (multi-class).

"""

categorical_col = pd.DataFrame()
numerical_col = pd.DataFrame()

for col in df:
  if (df[col].dtype=='int64') & (col != 'Exam_Score'):
    numerical_col[col] = df[col]
  elif (df[col].dtype=='object') & (col != 'Exam_Score'):
    categorical_col[col] = df[col]

categorical_col.head()
# numerical_col.head()

from sklearn.preprocessing import LabelEncoder, OneHotEncoder
le = LabelEncoder()
one = OneHotEncoder()

for col in categorical_col:
  if (len(categorical_col[col].unique()) == 2) :
    df[col] = le.fit_transform(df[col])
  else:
    df = pd.get_dummies(df, columns=[col], prefix=[col], drop_first=True)

for col in df:
  df[col] = df[col].astype(int)
df.head()

"""## Scaled numerical columns using StandardScaler."""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

for col in numerical_col:
  df[col] = scaler.fit_transform(numerical_col[[col]])
  print(f'{col} have values==  {df[col].min()} and {df[col].max()}')

for col in df:
  print(f'{col} have values==  {df[col].min()} and {df[col].max()}')

df.shape

"""# Visualization (EDA)

## Histograms of numeric variables
"""

# Histograms for numeric columns
numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns

# Calculate the number of rows needed
n_cols = len(numeric_cols)
n_rows = (n_cols + 3) // 4 # Calculate rows needed for a 4-column grid

plt.figure(figsize=(15, n_rows * 3)) # Adjust figure height based on rows
for i, col in enumerate(numeric_cols, 1):
    plt.subplot(n_rows, 4, i)
    plt.hist(df[col], bins=20, color='skyblue', edgecolor='black')
    plt.title(f'{col} Distribution')
plt.tight_layout()
plt.show()

"""## Scatter plots (Study Hours vs Exam Score)"""

plt.figure(figsize=(6, 5))
plt.scatter(df['Hours_Studied'], df['Exam_Score'], alpha=0.6, color='purple')
plt.title("Study Hours vs Exam Score")
plt.xlabel("Hours Studied")
plt.ylabel("Exam Score")
plt.grid(True, linestyle='--', alpha=0.5)
plt.show()

"""## Boxplots (Preparation vs Exam Score)

"""

plt.figure(figsize=(7, 5))
sns.boxplot(x='Parental_Involvement', y='Exam_Score', data=dff, palette="Set2")
plt.title("Parental Involvement vs Exam Score")
plt.xlabel("Parental Involvement")
plt.ylabel("Exam Score")
plt.show()

"""## Heatmap (feature correlation with Exam Score)"""

plt.figure(figsize=(12, 8))
corr = df.corr()
sns.heatmap(corr, annot=False, cmap="coolwarm", linewidths=0.5)
plt.title("Feature Correlation Heatmap")
plt.show()

# Focus only on Exam_Score correlation
plt.figure(figsize=(6, 6))
exam_corr = corr[['Exam_Score']].sort_values(by='Exam_Score', ascending=False)
sns.heatmap(exam_corr, annot=True, cmap="viridis", cbar=False)
plt.title("Correlation of Features with Exam Score")
plt.show()

"""# Model Training (Linear Regression)

## Train/Test Split: 80% training, 20% testing


"""

X = df.drop('Exam_Score', axis=1)
y = df['Exam_Score']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""## Model: Linear Regression"""

model = LinearRegression()

model.fit(X_train, y_train)

pred = model.predict(X_test)

"""## Performance:"""

mse = mean_squared_error(y_test, pred)
r2 = r2_score(y_test, pred)

print(f"Mean Squared Error: {mse}")
print(f'Root mean sqr: {np.sqrt(mse)}')
print(f"R-squared: {r2}")

# Error distribution
residuals = y_test - pred # Calculate residuals
plt.figure(figsize=(8, 6))
sns.histplot(residuals, bins=20, kde=True, color="orange")
plt.axvline(0, color="red", linestyle="--")
plt.title("Distribution of Residuals")
plt.xlabel("Residuals")
plt.ylabel("Frequency")
plt.show()

"""# 5. Polynomial Regression (degree=2)

MSE: 3.5745

RMSE: 1.8906

RÂ²: 0.7471

ðŸ‘‰ Polynomial regression performed worse than linear â€” suggesting linear relationships dominate.
"""

from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score
import numpy as np

# Polynomial features (degree=2 to start)
poly = PolynomialFeatures(degree=2, include_bias=False)
X_poly = poly.fit_transform(X_train)

lin_reg = LinearRegression()
lin_reg.fit(X_poly, y_train)

# Predictions
y_pred_poly = lin_reg.predict(poly.transform(X_test))

# Evaluation
mse_poly = mean_squared_error(y_test, y_pred_poly)
rmse_poly = np.sqrt(mse_poly)
r2_poly = r2_score(y_test, y_pred_poly)

print("Polynomial Regression (degree=2)")
print(f"Mean Squared Error: {mse_poly}")
print(f"Root Mean Squared Error: {rmse_poly}")
print(f"R-squared: {r2_poly}")

"""# 6. Feature Importance / Ablation Study

All Features: RÂ² = 0.7696

Drop Sleep: RÂ² = 0.7698 (slightly better, Sleep adds no value)

Drop Participation: RÂ² = 0.7662 (worse, Participation is important)

Drop Both: RÂ² = 0.7664 (worse, confirms Participation matters more)
"""

from sklearn.metrics import mean_squared_error, r2_score

def evaluate_model(features):
    X_train_sub = X_train[features]
    X_test_sub = X_test[features]

    model = LinearRegression()
    model.fit(X_train_sub, y_train)
    preds = model.predict(X_test_sub)

    mse = mean_squared_error(y_test, preds)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, preds)

    return mse, rmse, r2

# Example feature sets
feature_sets = {
    "All Features": X_train.columns,
    "Drop Sleep": [f for f in X_train.columns if f != "Sleep_Hours"],
    "Drop Participation": [f for f in X_train.columns if f != "Extracurricular_Activities"],
    "Drop Both": [f for f in X_train.columns if f not in ["Sleep_Hours", "Extracurricular_Activities"]],
}

for name, features in feature_sets.items():
    mse, rmse, r2 = evaluate_model(features)
    print(f"\n{name}:")
    print(f"MSE: {mse:.4f}, RMSE: {rmse:.4f}, R2: {r2:.4f}")